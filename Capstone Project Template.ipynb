{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "## Project Summary\n",
    "\n",
    "This is the capstone project for Udacity Data engineer nanodegree. In this project, I will explore I94 Immigration data and create a database that is optimized to query and analyze immigration events. An ETL pipeline is to be build with these to data sources to create the database to store the immigrants information\n",
    "\n",
    "The project follows the follow steps:\n",
    "\n",
    "Step 1: Scope the Project and Gather Data  \n",
    "Step 2: Explore and Assess the Data  \n",
    "Step 3: Define the Data Model  \n",
    "Step 4: Run ETL to Model the Data  \n",
    "Step 5: Complete Project Write Up  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The scope of this project:\n",
    "For this project, I would like to explore the profiles of new immigrants and explore what the new immigrants value when they make their choice on which city to land on. I will create a immigrant table as the first dimensional table, which shows the profile of immigrants. I will aggregate the I94 immigration data by destination city as well as aggregate city temperature data by city to create the city table as second-dimension table. For the fact table, I will create the the table that shows the immigrant event in I94 immigration data. Lastly,I will create a database to query on immigration events. All the process are conducted in Spark.\n",
    "\n",
    "### Describe and Gather Data\n",
    "•\tI94 Immigration Data: This data comes from the US National Tourism and Trade Office. \n",
    "\n",
    " |-- cicid: double (nullable = true)  \n",
    " |-- i94yr: double (nullable = true)  \n",
    " |-- i94mon: double (nullable = true)  \n",
    " |-- i94cit: double (nullable = true)  \n",
    " |-- i94res: double (nullable = true)  \n",
    " |-- i94port: string (nullable = true)  \n",
    " |-- arrdate: double (nullable = true)  \n",
    " |-- i94mode: double (nullable = true)  \n",
    " |-- i94addr: string (nullable = true)  \n",
    " |-- depdate: double (nullable = true)  \n",
    " |-- i94bir: double (nullable = true)  \n",
    " |-- i94visa: double (nullable = true)  \n",
    " |-- count: double (nullable = true)  \n",
    " |-- dtadfile: string (nullable = true)  \n",
    " |-- visapost: string (nullable = true)  \n",
    " |-- occup: string (nullable = true)  \n",
    " |-- entdepa: string (nullable = true)  \n",
    " |-- entdepd: string (nullable = true)  \n",
    " |-- entdepu: string (nullable = true)  \n",
    " |-- matflag: string (nullable = true)  \n",
    " |-- biryear: double (nullable = true)  \n",
    " |-- dtaddto: string (nullable = true)  \n",
    " |-- gender: string (nullable = true)  \n",
    " |-- insnum: string (nullable = true)  \n",
    " |-- airline: string (nullable = true)  \n",
    " |-- admnum: double (nullable = true)  \n",
    " |-- fltno: string (nullable = true)  \n",
    " |-- visatype: string (nullable = true)  \n",
    "\n",
    "•\tWorld Temperature Data: This dataset came from Kaggle. \n",
    "    dt  \n",
    "    AverageTemperature  \n",
    "    AverageTemperatureUncertainty  \n",
    "    City  \n",
    "    Country  \n",
    "    Latitude  \n",
    "    Longitude  \n",
    "\n",
    "•\tU.S. City Demographic Data:\n",
    "    City  \n",
    "    State  \n",
    "    Median Age  \n",
    "    Male Population  \n",
    "    Female Population  \n",
    "    Total Population  \n",
    "    Number of Veterans  \n",
    "    Foreign-born  \n",
    "    Average Household Size  \n",
    "    State Code  \n",
    "    Race  \n",
    "    Count  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|9.247139923E10|00602|      B2|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247161383E10|00602|      B2|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|9.247079603E10|00602|      B2|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|9.247848973E10|00608|      B1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_spark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport = pd.read_csv('airport-codes_csv.csv' )\n",
    "df_airport.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city = pd.read_csv('us-cities-demographics.csv',delimiter = ';' )\n",
    "df_city.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'city'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citycode = pd.read_csv('city_code.txt',sep=\"=\")\n",
    "df_citycode.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Explore the Data¶\n",
    "I94 immigration data - We wil drop data points with the city code i94cit is not a valid value. This is described in I94_SAS_Labels_Description.SAS\n",
    "\n",
    "U.S. City Demographic Data: City  - we will drop the city with not in the list in the city code i94cit\n",
    "\n",
    "Temperature Data - We will filter the country to US, drop data points with null AverageTemperature and aggregate the average averageTemperature by  city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore Immigrants data\n",
    "df_spark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing value in i94cit\n",
    "df_spark.where(df_spark[ 'i94cit' ] == '').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citycode = df_citycode['code'].tolist()\n",
    "len(citycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark= df_spark.withColumn('i94cit', df_spark[ 'i94cit' ].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2702245"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 2702245 records out of 3096313 have  valid city code\n",
    "df_immigration = df_spark.filter(df_spark.i94cit.isin(citycode))\n",
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore temperature data\n",
    "# There are 8599212 records\n",
    "df_temp = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8235082"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After filtering out data points with NaN average temperature\n",
    "# There are 8235082 records\n",
    "df_temp = df_temp.filter(df_temp.AverageTemperature != 'NaN')\n",
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+\n",
      "|           City|avg(AverageTemperature)|\n",
      "+---------------+-----------------------+\n",
      "|      Worcester|      7.341440525809558|\n",
      "|     Charleston|     18.696557871112546|\n",
      "|         Corona|      16.12483712696008|\n",
      "|    Springfield|     10.647931343609901|\n",
      "|          Tempe|       21.0487690509584|\n",
      "|North Las Vegas|      17.45498153547133|\n",
      "|       Thornton|      8.777836262323191|\n",
      "|        Phoenix|       21.0487690509584|\n",
      "|      Hollywood|      23.06892444289695|\n",
      "| Pembroke Pines|      23.06892444289695|\n",
      "|       Savannah|     19.406439563962774|\n",
      "|     Toms River|     11.855868547611408|\n",
      "|  Coral Springs|      23.06892444289695|\n",
      "|          Omaha|     10.051168201978832|\n",
      "|      Anchorage|    -2.3016456107756667|\n",
      "|       Paradise|      17.45498153547133|\n",
      "|      Allentown|      9.523295607566514|\n",
      "|   Fort Collins|       8.18163890045814|\n",
      "|        Anaheim|      16.12483712696008|\n",
      "|     Greensboro|      14.41886117345303|\n",
      "+---------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After aggreate the averageTemperature\n",
    "df_temp = df_temp.where(F.lower(F.col('Country')) == 'united states')\\\n",
    "                    .groupBy('City')\\\n",
    "                    .agg(F.mean('AverageTemperature'))\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 3490 information for city's temperature\n",
    "df_temp= df_temp.withColumn('AverageTemperature',F.round(df_temp[\"avg(AverageTemperature)\"], 2))\\\n",
    "                .drop('avg(AverageTemperature)')\n",
    "                \n",
    "df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean city demo table\n",
    "# There are 2891 records\n",
    "df_city = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"us-cities-demographics.csv\")\n",
    "df_city.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|   City|   State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race| Count|\n",
      "+-------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "|Yonkers|New York|      38.0|          96580|           104538|          201118|              4801|       61247|                   2.8|        NY|  Hispanic or Latino| 73608|\n",
      "|Yonkers|New York|      38.0|          96580|           104538|          201118|              4801|       61247|                   2.8|        NY|Black or African-...| 38731|\n",
      "|Yonkers|New York|      38.0|          96580|           104538|          201118|              4801|       61247|                   2.8|        NY|               Asian| 13981|\n",
      "|Yonkers|New York|      38.0|          96580|           104538|          201118|              4801|       61247|                   2.8|        NY|               White|129492|\n",
      "|Yonkers|New York|      38.0|          96580|           104538|          201118|              4801|       61247|                   2.8|        NY|American Indian a...|  1112|\n",
      "+-------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are 596 unique city but over 3000 records in city table\n",
    "# I found there are multiple entry of race and corresponding every city\n",
    "df_city.filter(df_city.City == 'Yonkers').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.select('City','State').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We would like to pivot race and count to make city as unique key in this table\n",
    "df_city = df_city.withColumn('Count',df_city.Count.cast('integer'))\n",
    "df_city = df_city.groupby('City',\n",
    " 'State',\n",
    " 'Median Age',\n",
    " 'Male Population',\n",
    " 'Female Population',\n",
    " 'Total Population',\n",
    " 'Number of Veterans',\n",
    " 'Foreign-born',\n",
    " 'Average Household Size',\n",
    " 'State Code').pivot('Race').max('Count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change data type\n",
    "df_city= df_city.withColumn('Median Age', F.round(F.col('Median Age').cast('float'),2)) \\\n",
    "                .withColumn('Male Population', F.col('Male Population').cast('integer')) \\\n",
    "                .withColumn('Female Population', F.col('Female Population').cast('integer')) \\\n",
    "                .withColumn('Total Population', F.col('Total Population').cast('integer')) \\\n",
    "                .withColumn('Number of Veterans', F.col('Number of Veterans').cast('integer')) \\\n",
    "                .withColumn('Average Household Size', F.round(F.col('Average Household Size').cast('float'),2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: float (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: float (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- American Indian and Alaska Native: integer (nullable = true)\n",
      " |-- Asian: integer (nullable = true)\n",
      " |-- Black or African-American: integer (nullable = true)\n",
      " |-- Hispanic or Latino: integer (nullable = true)\n",
      " |-- White: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_city.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 3.1 Conceptual Data Model\n",
    "#### Fact Table - Contain information from the I94 immigration data showing the immigrant events  \n",
    "\n",
    "Columns:    \n",
    "cicid -- primary key  \n",
    "i94yr  \n",
    "i94mon  \n",
    "i94cit   \n",
    "i94port  \n",
    "arrdate  \n",
    "i94mode   \n",
    "depdate   \n",
    "i94visa   \n",
    "airline  \n",
    "visatype  \n",
    "\n",
    "#### Dimension Table  - This will contain information of immigrants profile. The columns is selected from I94 immigration data\n",
    "\n",
    "Columns:  \n",
    "cicid --primary key    \n",
    "i94cit  \n",
    "i94res  \n",
    "i94addr   \n",
    "i94bir  \n",
    "occup  \n",
    "biryear  \n",
    "gender  \n",
    "\n",
    "\n",
    "#### Dimension Table 2 - This will contain the information of city they arrived. The table will created by join city temperature and city demographic table\n",
    "\n",
    "Columns:\n",
    "City -- primary key  \n",
    "State   \n",
    "Median Age    \n",
    "Total Population   \n",
    "Foreign-born   \n",
    "Average Household Size   \n",
    "State Code   \n",
    "American Indian and Alaska Native   \n",
    "Asian   \n",
    "Black or African-American   \n",
    "Hispanic or Latino   \n",
    "White   \n",
    "AverageTemperature   \n",
    "\n",
    "\n",
    "### 3.2 Mapping Out Data Pipelines\n",
    "Pipeline Steps:\n",
    "\n",
    "1. Clean I94 data to create Spark dataframe df_immigration.  \n",
    "2. Clean city demographic data to create spark datafram df_city.  \n",
    "3. Clean temperature data to create Spark dataframe df_temp.  \n",
    "4. Create fact table tables and write to parquet file partitioned by i94port.  \n",
    "5. Create immigrats profile table by selecting relevant columns from df_immigration and write to parquet file partitioned by i94cit.  \n",
    "6. Create city dimension table by joining df_temp to df_city and write to parquet file .  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### STEP 1 Create Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read Spark dataframe of immigrant data \n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_citycode = pd.read_csv('city_code.txt',sep=\"=\")\n",
    "citycode = df_citycode['code'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "df_spark= df_spark.withColumn('i94cit', df_spark[ 'i94cit' ].cast('integer'))\n",
    "df_immigration = df_spark.filter(df_spark.i94cit.isin(citycode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns for immigration fact table\n",
    "fact_table = df_immigration.select([\"cicid\",\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\",\"airline\",\"visatype\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write immigration dimension table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/result/fact.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 2 Create Dimension Table - Immigrants Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract columns for temperature dimension table\n",
    "immigrants_table = df_immigration.select([\"cicid\", \"i94cit\", \"i94res\",\"i94addr\",\"i94bir\",\"occup\",\"biryear\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write temperature dimension table to parquet files partitioned by i94port\n",
    "immigrants_table.write.mode(\"append\").partitionBy(\"i94cit\").parquet(\"/results/immigrats.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### STEP 3 Create Dimension Table - City "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the fact table by joining the immigration and temperature views\n",
    "city_table =df_city.join(df_temp, F.lower(df_city.City) == F.lower(df_temp.City) , how='left').drop(df_temp.City)\n",
    "city_table = city_table.select('City', \n",
    "'State',\n",
    "'Median Age',\n",
    "'Total Population',\n",
    "'Foreign-born',\n",
    "'Average Household Size',\n",
    "'State Code',\n",
    "'American Indian and Alaska Native',\n",
    "'Asian',\n",
    "'Black or African-American',\n",
    "'Hispanic or Latino',\n",
    "'White',\n",
    "'AverageTemperature')\n",
    "city_table = city_table.withColumnRenamed('Median Age','Median_Age') \\\n",
    "                        .withColumnRenamed('Total Population','Total_Population') \\\n",
    "                        .withColumnRenamed('Foreign-born','Foreign_Born') \\\n",
    "                        .withColumnRenamed('Average Household Size','Average_Household_Size',) \\\n",
    "                        .withColumnRenamed('State Code','State_Code',) \\\n",
    "                        .withColumnRenamed('American Indian and Alaska Native','American_Native',) \\\n",
    "                        .withColumnRenamed('Black or African-American','African_American') \\\n",
    "                        .withColumnRenamed('Hispanic or Latino','Hispanic_Latino') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table to parquet files partitioned by i94port\n",
    "city_table.write.mode(\"append\").parquet(\"/results/city.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you ll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def quality_check(df, table_name, primary_key):\n",
    "    '''\n",
    "    Input: Spark dataframe, table_name, primary key of each table\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    \n",
    "    row_count = df.count()\n",
    "    primary_key_count = df.select(*primary_key).distinct().count()\n",
    "    \n",
    "    if row_count == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(table_name))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(table_name, row_count))\n",
    "        \n",
    "    if row_count == primary_key_count:\n",
    "        print (\"Data quality check passed for{} with unique primary key{}\".format(table_name, primary_key))\n",
    "    else:\n",
    "        print (\"Data quality check failed for {} with primary key{}\".format(table_name, primary_key))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for fact table with 2702245 records\n",
      "Data quality check passed forfact table with unique primary key['cicid']\n",
      "Data quality check passed for immigrants profile table with 2702245 records\n",
      "Data quality check passed forimmigrants profile table with unique primary key['cicid']\n",
      "Data quality check passed for city table with 596 records\n",
      "Data quality check passed forcity table with unique primary key['city', 'state']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform data quality check\n",
    "quality_check(fact_table, \"fact table\",[\"cicid\"])\n",
    "quality_check(immigrants_table, \"immigrants profile table\",[\"cicid\"])\n",
    "quality_check(city_table, \"city table\",[\"city\",\"state\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.3 Data dictionary \n",
    "\n",
    "#### Fact Table - This will contain information from the I94 immigration data showing the immigrant events\n",
    "\n",
    "Columns:    \n",
    "cicid -- primary key  \n",
    "i94yr = 4 digit year  \n",
    "i94mon = numeric month  \n",
    "i94cit = 3 digit code of origin city  \n",
    "i94port = 3 character code of destination city  \n",
    "arrdate = arrival date  \n",
    "i94mode = 1 digit travel code  \n",
    "depdate = departure date  \n",
    "i94visa = reason for immigratio  \n",
    "airline  = airline taken  \n",
    "visatype  = type of visa  \n",
    "\n",
    "#### 1st Dimension Table - This will contain information of immigrants profile. The columns is selected from I94 immigration data\n",
    "\n",
    "Columns:  \n",
    "cicid --primary key        \n",
    "i94cit = origin city of immigrants  \n",
    "i94res =  residience of immigrants  \n",
    "i94addr = addresss  of immigrants  \n",
    "i94bir  = birth date of immigrants  \n",
    "occup  = occupation of immigrants  \n",
    "biryear  = the year of birth of immigrants  \n",
    "gender = immigrants gender   \n",
    "\n",
    "\n",
    "#### 2nd Dimension Table - This will contain the information of city they arrived. The table will created by join city temperature and city demographic table\n",
    "\n",
    "Columns:\n",
    "City -- primary key    \n",
    "State -- primary key   \n",
    "Median Age = the average age  \n",
    "Total Population  = total population of the city  \n",
    "Foreign-born   = the population borned in foreign country  \n",
    "Average Household Size = average household size    \n",
    "State Code  = the code of state  \n",
    "American Indian and Alaska Native = the number of race American Indian and Alaska Native  \n",
    "Asian  = the number of race Asian  \n",
    "Black or African-American = the number of race  Black or African-American  \n",
    "Hispanic or Latino    = the number of race Hispanic or Latino  \n",
    "White = the number of race White  \n",
    "AverageTemperature  = the average temperature of the city  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n",
    "#### The rationale for the choice of tools and technologies for the project.\n",
    "For this project, Spark was used because it is efficient to handle multiple file formats (SAS, csv) with large amounts of data. To reach the goal of creating a database of immigrants information, Spark SQL was used to process the input raw files into dataframes and manipulated those data via spark function.\n",
    "\n",
    "For example, Spark is useful in cleaning large number of raw data and aggregate the data. For example, the command 'df_immigration = df_spark.filter(df_spark.i94cit.isin(citycode))' filtered out the invalid values in the city code.   \n",
    "The command \"df_temp = df_temp.where(F.lower(F.col('Country')) == 'united states').groupBy('City').agg(F.mean('AverageTemperature'))\" got the average temperature of each city in each country. By using these function, we can conduct the data cleaning tasks to prepare the data for creating fact table and dimension tables.\n",
    "\n",
    "Spark is also very important when it comes to creating tables. The select funtion and join function enable to get the right features for each table. The withColumn function and withColumnRenamed helped to make the column in an appropriated format.\n",
    "\n",
    "Last but not least, Spark plays an important role when writing the final table. For example, \"immigrants_table.write.mode(\"append\").partitionBy(\"i94cit\").parquet(\"/results/immigrats.parquet\")\" the command helps to write the big immigrants table to database in an more organized way so analyst can retrieve those data more efficiently by filtering the city code. It improve the efficiecny and save time in the future work.\n",
    "\n",
    "\n",
    "#### Data updated and the reason\n",
    "Since the format of the raw files in monthly format, we should continue pulling the data monthly.\n",
    "\n",
    "#### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "1. If the data was increased by 100x:  \n",
    "We can store the raw data in S3 and load data into Redshift when we would like to do the analysis every month because Redshift is optimized for aggregation and read-heavy workloads  \n",
    "\n",
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day:  \n",
    "AirFlow is an ideal tool to create dashboard for data pipeline and it can create DAG retries or send emails when failure happens so that data engineer can fix the problem on time.  \n",
    "\n",
    "3. The database needed to be accessed by 100+ people:  \n",
    "The more people accessing the database the more cpu resources you need to get a fast experience. By using a distributed database you can to improve your replications and partitioning to get faster query results for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
